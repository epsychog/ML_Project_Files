<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>How Well Do Weight Lifting Exercises are Performed?</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>





</head>

<body>
<h1>How Well Do Weight Lifting Exercises are Performed?</h1>

<h2>Synopsis</h2>

<p>The current report is a project aiming to predict the manner in which a person performed a weight lifting exercise. The data for this analysis was collected from sensors fitted onto specific parts of the body of 6 participants while performing the exercise.</p>

<p>For this analysis we tried 5 different prediction models and concluded that the <strong>Random Trees</strong> algorithm was the one that gave the best accuracy prediction (<strong>&gt;95%</strong>) and the lower out of sample error (<strong>&lt;5%</strong>)</p>

<h2>Data Processing &amp; Model Selection</h2>

<h3>Pre-Processing &amp; Data Cleaning</h3>

<p>The data for this project comes from <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>.</p>

<p>We started by examining the variables in the training and test data sets in order to decide which variables to use when training our model. We removed all columns that had a majority of NA values and all columns of class &ldquo;factor&rdquo;. We also removed the column &ldquo;X&rdquo;.</p>

<p>At the end of the data processing we ensured that both data sets (training and test) had the same columns selected with the only difference the outcome variable which was column <strong>classe</strong> in the training set and the column <strong>problem_id</strong> in the test set.</p>

<h3>Splitting the Data</h3>

<p>We split the training data set into 3 parts</p>

<ul>
<li>training (60%)</li>
<li>cross-validation (20%)</li>
<li>test (20%)</li>
</ul>

<h3>Model Fitting &amp; Selection</h3>

<p>We selected 5 models to test with our data set based on the following criteria:</p>

<ol>
<li>The type of project that each method was most suitable for (i.e. Classification, Regression or Both). </li>
<li>Our familiarity with the model.</li>
</ol>

<p>As our project involves a classification project, we selected only models suitable for either Classification or for both classification and regression. Specifically, the models tested were the following:</p>

<ul>
<li>Decision Trees (rpart)</li>
<li>Random Forests (rf)</li>
<li>Boosting with Trees (gbm)</li>
<li>Linear Discriminant Analysis (lda)</li>
<li>Naive Bayes (nb)</li>
</ul>

<p>Initially we tried to train our models on the training partition we created which corresponded to 60% of the training set. However we found that the algorithms Random Forests, GBM and Naive Bayers were taking a very long time to run so we decided to training our algorithm on 1000 observations selected randomly from the training partition we created.</p>

<p>We trained each of the 5 models on the 100 observations and checked the accuracy of each one using the test partition we created form the training set.</p>

<p>The summarised accuracy results from each model trained are shown below:</p>

<ol>
<li>Decision Trees (rpart): <strong>0.5029314</strong></li>
<li>Random Forests (rf): <strong>0.9576854</strong></li>
<li>Boosting with Trees (gbm): <strong>0.956156</strong></li>
<li>Linear Discriminant Analysis (lda): <strong>0.7035432</strong></li>
<li>Naive Bayes (nb): <strong>0.6721897</strong></li>
</ol>

<p>The models that give the best accuracy were the <strong>Random Forests</strong> and <strong>Boosting with Trees (gbm)</strong>. The Random Forest accuracy was a slightly better and this is why we chose this model.</p>

<h3>Cross Validation</h3>

<p>The process for cross-validation that we followed consists of the following steps:</p>

<ol>
<li>Split the training data set into 3 parts: training, cross validation and test. </li>
<li>Used 1000 observations from the &ldquo;training&rdquo; partition of our training dataset to train our 5 models</li>
<li>Used the &ldquo;test&rdquo; partition of our training dataset as an independent set to predict the <strong>classe</strong> variable and check the prediction accuracy of each of the 5 models</li>
<li>Used the &ldquo;cross-validation&rdquo; partition of our training dataset ONLY ONCE with the selected model (Random Forests) and got the out of sample error.</li>
</ol>

<h3>Estimation of Out of Sample Error</h3>

<p>Our estimated out of sample error was <strong>0.04537344</strong> and was derived from the accuracy returned when we run our selected model (Random Forests) on the &ldquo;cross-validation&rdquo; partition of our training dataset.</p>

<h2>Conclusion</h2>

<p>The <strong>Random Forests</strong> algorithm was the algorithms that performed best among the 5 different prediction models that were tested. The Random Trees algorithm gave the best accuracy prediction (<strong>&gt;95%</strong>) and the lower out of sample error (<strong>&lt;5%</strong>).</p>

</body>

</html>

